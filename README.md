# LLMConsole

*Intuitive framework to combine the utility of the console/terminal with the power of large language models*



LLMConsole utilizes-
* xonsh
* pyautogen
* selenium
  

STARTING XONSH & LLMCONSOLE:
Hotkey listing
![alt text](https://github.com/05remla/repo_images/blob/main/getting_started.png)

CONVENIENT HOTKEY FOR QUICK CHAT:
Thanks to xonsh, we just press [ctrl]+[z]... then chat 
![alt text](https://github.com/05remla/repo_images/blob/main/hot%20keys%20and%20chat%201.png)

EASY CODE INSERT:
if LLM returns code, you can insert that code as your input with [ctrl]+[x]
![alt text](https://github.com/05remla/repo_images/blob/main/hot%20keys%20(cody%20insert).png)

TEACHING:
Here we know the LLM is not familiar with the 4090's specs. We make a simply query to get links, ask the LLM what two links are the most relavent, then scrape those sites. We then ask the LLM to compress (summerize) that info down to X characters. Voila! The LLM is now educated on RTX 4090 specs.
![alt text](https://github.com/05remla/repo_images/blob/main/teaching.png)
