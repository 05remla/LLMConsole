# LLMConsole

*Intuitive framework to combine the utility of the console/terminal with the power of large language models*

# ![Pre-Release 0.0.1](https://github.com/05remla/LLMConsole/releases/tag/PR-0.0.1)



LLMConsole utilizes-
* xonsh
* pyautogen
* selenium
* duckduckgo_search
* openai  

STARTING XONSH & LLMCONSOLE:

Hotkey listing

![alt text](https://github.com/05remla/repo_images/blob/main/getting_started.png)



CONVENIENT HOTKEY FOR QUICK CHAT:

Just press [ctrl]+[z]... then chat 

![alt text](https://github.com/05remla/repo_images/blob/main/hot%20keys%20and%20chat%201.png)



EASY CODE INSERT:

If LLM returns code, you can insert that code as your input with [ctrl]+[x]

![alt text](https://github.com/05remla/repo_images/blob/main/hot%20keys%20(cody%20insert).png)



TEACHING:

Here we see the LLM is not familiar with the topic. We make a simply query to get links, ask the LLM what two links are the most relavent, then scrape those sites. We then ask the LLM to compress (summerize) that info down to X characters.

![alt text](https://github.com/05remla/repo_images/blob/main/teaching3.png)



![alt text](https://github.com/05remla/repo_images/blob/main/teaching4.png)

Voila! It's a little smarter now.

